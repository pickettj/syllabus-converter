





### Learning Outcomes

The ultimate goal of this course is to develop *critical thinking skills* and *habits of mind* for evaluating the relationship between primary sources (data), fact, and analytical implications: How do we know what we think we know? What is a fact? When everyone has an opinion, what is the difference between a more compelling and less compelling argument?

This may seem vague, and to some degree this is what all humanities courses purport to do. What about the "hard skills" you can put on your resume?

#### Analytical Writing

Reports of the demise of analytical writing are greatly exaggerated: for all the ways AI is reshaping the way we write (see below), your ability to draw upon facts to advance an argument-driven interpetation of those facts (in print or out loud; in an academic essay or on social media; to a friend or to your supervisor) is more valuable than ever before.

#### "Knowing Stuff"

Can you name all of the US state capitals? Your p̶a̶r̶e̶n̶t̶s̶ grandparents probably could, or memorized them in school. As more and more information is at our disposal on our smartphones, less and less of it is readily available in our heads. For the most part, that is as it should be: pedagogy evolves along with our tools.

However... it is still important to have some baseline of knowledge in your active memory. Even though you can look up a fact in a matter of seconds, in practice much of the time you will not do so: when you are chatting on the phone, as you quickly peruse an article, when you don't know what you don't know. The facts at your immediate disposal in your active memory shape your understanding of the world around you even when you don't realize it.

Therefore, you will be expected to learn some stuff — even (gasp) memorize a few big-picture facts — relevant to the subjectmatter of this course.



### Artificial Intelligence / Large Language Models

#### Philosophical Approach

What you refer to as 'AI' is more specifically a Large Language Model or LLM: essentially, these systems are trained on vast corpora of human-produced text to identify statistical patterns in language. LLMs can generate remarkably coherent responses to queries, though they don't truly 'understand' content the way humans do. This potent technology is transforming every field, and history is no exception.

In history classes of yore (i.e., just several years ago), many collegiate history classes would have featured tasks such as assembling a literature review, writing an analytical essay, or deriving insights from a primary source. Because these tasks are all closely related to textual corpora, LLMs are quite good at them, which means we as historians now have a powerful new tool at our disposal — which you will make use of in this course.

Especially in the short term, this scale of change is threatening, and creates new challenges of intellectual honesty and course policies: How do we differentiate between your intellectual labor and that of the LLM? What is the point of artificially separating you from a tool that you will have in the "real world"?  These questions have forced humanists and social scientists (historians are both) to reconsider what is at the core of the field: a critical assessment of what constitutes historical evidence, and making sense of that evidence through analytical reasoning. AI shifts the focus away from the *products* of these pursuits and toward *research skills* and *habits of mind*: the fact that a machine can now competently produce an analytical essay with no grammatical errors and based on primary sources makes an ability to critically evaluate those products more important than ever.

#### AI Policy

This course embraces the "broad use" level of AI [policy specified by the Center for Teaching and Learning](https://teaching.pitt.edu/resources/teaching-with-generative-ai/):

> The use of Generative AI tools, including ChatGPT, is encouraged/permitted in this course for students who wish to use them. You may choose to use AI tools to help brainstorm assignments or projects or to revise existing work you have written. However, to adhere to scholarly values, students must cite any AI-generated material that informed their work (this includes in-text citations and/or use of quotations, and in your reference list). Using an AI tool to generate content without proper attribution qualifies as academic dishonesty.

In practice, however, these guidelines are more difficult to follow than it may seem at first because there is such a broad spectrum of AI usage. What if you write your own essay, but ask an LLM to improve the formatting and check it for sentence clarity and spelling errors? Does that require acknowledgement? What if you asked the LLM to identify the "most important" sections of a primary source?

There are no easy answers to these questions, and expectations will vary widely between courses. In this class, I take it for granted that you will use LLMs to assist with tasks such as formatting, grammatical / syntactical accuracy, and even basic brainstorming: unless an assignment specifically requests it, you do not need to offer an explicit acknowledgment. A question you should be asking is: did the computer shape my conceptual understanding of this source or scholarly work? Is my creative output inspired in a fundamental way by the AI? In a sense, these quandaries are not new: if you got your idea from somewhere else, you need to cite your source, and there have always been edge cases. When in doubt, err on the side of transparency.

Your instructor is bound by these same principles when preparing course material and offering feedback. I may use LLM assistance to help format slides and to reconfigure the presentation of my feedback. However, I will never feed any of your material into an LLM not [approved for broad use by Pitt](https://www.technology.pitt.edu/ai) (i.e., to avoid privacy concerns); the content and phrasing of all feedback will always come directly from me; and I will never use an LLM to determine, or even suggest, a grade.

#### LLMs as Assistants for Learning History

The following are some legitimate use cases (and words of caution) for using AI in the field of history:

- *Summarize a book or article*: LLMs are very effective at this task (and the library e-reader already does this automatically). In the face of time constraints, we have always been skimming and "extracting" information from texts without reading: now we can do it even better, and doing so is not "cheating."
  - *Caution*: LLMs are not as effective at noticing when a detail not explicitly tied to the theme or thesis of a work matters. In history especially, the details still matter, and those insights must come from you: close reading still matters.
- *Identify stylistic / grammatical / syntactical errors in an essay*: The LLMs can identify the ways your writing is different or similar to a massive body of published work, which *often* equates to spotting legitimate errors. You can learn from this tool, so use it.
  - *Caution*: Remember that you can ask an interactive chatbot for further explanation of a suggestion. If you are blindly adopting writing suggestions without learning the underlying principle, you will reproduce errors.
- *Help me develop a coding tool*: With AI













